{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8526859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3428f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(os.path.dirname(os.getcwd()), \"CODE/Log\")\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "log_file_path = os.path.join(log_dir, \"predict.log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a36e2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    filename=log_file_path,\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7433d457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model_path):\n",
    "    logging.info(f\"Loading model from {model_path}...\")\n",
    "    model = joblib.load(model_path)\n",
    "    logging.info(\"Model loaded successfully.\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d45c6089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_preprocessor(preprocessor_dir,timestamp):\n",
    "    logging.info(f\"Loading preprocessor objects from {preprocessor_dir}...\")\n",
    "\n",
    "    # Load all preprocessing objects\n",
    "    scaler = joblib.load(os.path.join(preprocessor_dir, f\"scaler_{timestamp}.pkl\"))\n",
    "    label_encoders = joblib.load(os.path.join(preprocessor_dir, f\"label_encoders_{timestamp}.pkl\"))\n",
    "    imputer = joblib.load(os.path.join(preprocessor_dir, f\"imputer_{timestamp}.pkl\"))\n",
    "    removed_cols = joblib.load(os.path.join(preprocessor_dir, f\"removed_cols_{timestamp}.pkl\"))\n",
    "\n",
    "    logging.info(\"Preprocessor objects loaded successfully.\")\n",
    "    return scaler, imputer, label_encoders, removed_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86abd41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_new_data(data_dir, id_col):\n",
    "    logging.info(f\"Loading new data from {data_dir}...\")\n",
    "    new_data_path = os.path.join(data_dir, \"test.csv\")\n",
    "    new_data = pd.read_csv(new_data_path)\n",
    "\n",
    "    ids = new_data.pop(id_col)\n",
    "    logging.info(f\"New data and ID column loaded successfully.\")\n",
    "\n",
    "    return new_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a69f948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(new_data, scaler, imputer, encoder, removed_cols, id_col):\n",
    "    logging.info(\"Removing specified columns, including the ID column...\")\n",
    "\n",
    "    columns_to_remove = [col for col in removed_cols if col != id_col]\n",
    "    new_data = new_data.drop(columns=columns_to_remove, errors=\"ignore\")\n",
    "\n",
    "    logging.info(\"Applying imputer to fill missing values...\")\n",
    "    new_data_imputed = pd.DataFrame(\n",
    "        imputer.transform(new_data), columns=new_data.columns\n",
    "    )\n",
    "\n",
    "    logging.info(\"Applying label encoders for categorical columns...\")\n",
    "    for col, enc in encoder.items():\n",
    "        new_data_imputed[col] = enc.transform(new_data_imputed[col].astype(str))\n",
    "\n",
    "    logging.info(\"Scaling the data...\")\n",
    "    new_data_scaled = pd.DataFrame(\n",
    "        scaler.transform(new_data_imputed), columns=new_data_imputed.columns\n",
    "    )\n",
    "\n",
    "    if id_col in new_data_scaled.columns:\n",
    "        new_data_scaled = new_data_scaled.drop(columns=[id_col])\n",
    "\n",
    "    return new_data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1aa6ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_predictions(predictions, ids, predictions_dir, model_name, timestamp):\n",
    "    os.makedirs(predictions_dir, exist_ok=True)\n",
    "    prediction_name_with_time = f\"{model_name}_{timestamp}\"\n",
    "\n",
    "    predictions = pd.DataFrame({\"ID\": ids, \"Prediction\": predictions})\n",
    "\n",
    "    logging.info(f\"Saving predictions to {prediction_name_with_time}...\")\n",
    "    predictions.to_csv(prediction_name_with_time, index=False)\n",
    "    logging.info(\"Predictions saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc0e6853",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model_path, id_col, preprocessor_dir, data_dir, timestamp):\n",
    "    # Load the trained model\n",
    "    model = load_model(model_path)\n",
    "\n",
    "    # Load preprocessing objects\n",
    "    scaler, imputer, encoder, removed_cols = load_preprocessor(preprocessor_dir,timestamp)\n",
    "\n",
    "    # Load new data for prediction\n",
    "    new_data, ids = load_new_data(data_dir, id_col)\n",
    "\n",
    "    # Preprocess the new data\n",
    "    new_data_processed = preprocess_data(\n",
    "        new_data, scaler, imputer, encoder, removed_cols, id_col\n",
    "    )\n",
    "\n",
    "    # Make predictions\n",
    "    logging.info(\"Making predictions...\")\n",
    "    predictions = model.predict(new_data_processed)\n",
    "\n",
    "    # Save predictions\n",
    "    save_predictions(pd.DataFrame(predictions, columns=[\"Prediction\"]), timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f03d781e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -m MODEL -i ID_COL -p PREPROCESSOR -d\n",
      "                             DATA_DIR -t TIMESTAMP\n",
      "ipykernel_launcher.py: error: the following arguments are required: -m/--model, -i/--id_col, -p/--preprocessor, -d/--data_dir, -t/--timestamp\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=\"Make predictions using a trained model and preprocessor.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-m\", \"--model\", type=str, required=True, help=\"Path to the trained model.\"\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-i\",\n",
    "        \"--id_col\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Column Id where identified each row.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-p\",\n",
    "        \"--preprocessor\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory where the preprocessor objects are stored.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-d\",\n",
    "        \"--data_dir\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Directory where the new data is stored.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"-t\",\n",
    "        \"--timestamp\",\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"Timestamp when Makefile executed.\",\n",
    "    )\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    main(model_path=args.model, id_col=args.id_col, preprocessor_dir=args.preprocessor, data_dir=args.data_dir, timestamp=args.timestamp)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "MLOps",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
